{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6243c928-a3a8-4914-be6e-fb0a14d7d27d",
   "metadata": {
    "id": "6243c928-a3a8-4914-be6e-fb0a14d7d27d"
   },
   "source": [
    "# Projeto2: Deep Learning com PyTorch Para Classificação de Imagens\n",
    "# Autor: Ellihas Freitas\n",
    "# Realizado: 2026"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a89739da-74ce-46ba-9b4c-8b6f1d74f79d",
   "metadata": {
    "id": "a89739da-74ce-46ba-9b4c-8b6f1d74f79d"
   },
   "source": [
    "## 1. Instalação e Importação dos Pacotes Python\n",
    "\n",
    "https://pytorch.org"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8b95ae28-f23e-4112-b850-50ebe7cfcf5f",
   "metadata": {
    "id": "8b95ae28-f23e-4112-b850-50ebe7cfcf5f"
   },
   "outputs": [],
   "source": [
    "!pip install -q torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d1cc5206-7dca-4c73-b28c-18b4cbee2764",
   "metadata": {
    "id": "d1cc5206-7dca-4c73-b28c-18b4cbee2764"
   },
   "outputs": [],
   "source": [
    "!pip install -q torchvision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "76bbf489-6fa0-4bba-8d9a-ad8b3f26c954",
   "metadata": {
    "id": "76bbf489-6fa0-4bba-8d9a-ad8b3f26c954"
   },
   "outputs": [],
   "source": [
    "!pip install -q torchsummary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "817ed705-6297-44a8-a20b-53f0424236d2",
   "metadata": {
    "id": "817ed705-6297-44a8-a20b-53f0424236d2"
   },
   "outputs": [],
   "source": [
    "# Imports\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "from io import BytesIO\n",
    "from torchsummary import summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "eca424b4-b2fa-4958-bc33-0139d03dfffe",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "eca424b4-b2fa-4958-bc33-0139d03dfffe",
    "outputId": "084bb968-d99b-4fb2-cfcb-49f22ccbf30d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Author: Ellihas Freitas\n",
      "\n",
      "PIL         : 11.1.0\n",
      "matplotlib  : 3.10.0\n",
      "numpy       : 2.1.3\n",
      "torch       : 2.10.0\n",
      "torchsummary: 1.5.1\n",
      "torchvision : 0.25.0\n",
      "\n"
     ]
    }
   ],
   "source": [
    "%reload_ext watermark\n",
    "%watermark -a \"Ellihas Freitas\" --iversions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61d4a253-5757-474b-a73a-19e5b764c3a0",
   "metadata": {
    "id": "61d4a253-5757-474b-a73a-19e5b764c3a0"
   },
   "source": [
    "## 2. Definindo o Dispositivo (CPU ou GPU) Para Treinamento do Modelo de IA\n",
    "\n",
    "Leia o manual em pdf no Capítulo 13 do curso.\n",
    "\n",
    "Este projeto foi testado na nuvem com Google Colab (Free e Pro com GPU) e localmente com Laptop MacBook Pro M4 Max.\n",
    "\n",
    "Configurações de hardware:\n",
    "\n",
    "**Google Colab Free**\n",
    "\n",
    "- CPU: Intel(R) Xeon(R) CPU @ 2.00GHz 2-Core CPU\n",
    "- Mmemória RAM do Sistema: 12 GB de RAM\n",
    "- GPU: Tesla T4 (Modelo T4 com 15 GB de Memória)\n",
    "- Disco SSD\n",
    "  \n",
    "**Google Colab Pro**\n",
    "\n",
    "- CPU: Intel(R) Xeon(R) CPU @ 2.20GHz 12-Core CPU\n",
    "- Mmemória RAM do Sistema: 84 GB de RAM (ou 167 GB com High RAM)\n",
    "- GPU: NVIDIA A100 com 40 GB de Memória (ou 80 GB no High RAM)\n",
    "- Disco SSD\n",
    "<!-- Trabalho Desenvolvido no Curso da Data Science Academy - www.datascienceacademy.com.br -->\n",
    "**Laptop MacBook Pro M4 Max**\n",
    "\n",
    "- CPU: Apple M4 Max 16-Core CPU\n",
    "- Mmemória RAM do Sistema: 128 GB de RAM\n",
    "- GPU: GPU de 40 núcleos integrada ao processador\n",
    "- Disco SSD\n",
    "\n",
    "Nota: Se você tiver GPU Nvidia no seu computador e quiser usá-la para treinar modelos de Deep Learning você deve:\n",
    "\n",
    "1- Verificar o Compute Capability da GPU\n",
    "\n",
    "https://developer.nvidia.com/cuda-gpus\n",
    "\n",
    "2- Instalar o software CUDA\n",
    "\n",
    "https://developer.nvidia.com/cuda-downloads\n",
    "\n",
    "Outros tipos de GPUs podem ser usadas, mas podem requerer pacotes/softwares adicionais para serem configuradas com o PyTorch.\n",
    "\n",
    "-> Ao final do capítulo faremos uma comparação ao executar o projeto em diferentes tipos de hardware."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2b491bc-9d5a-4204-b156-bdb6b67b9477",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "c2b491bc-9d5a-4204-b156-bdb6b67b9477",
    "outputId": "83da5b38-001d-4c4c-bec7-c79de84a234a"
   },
   "outputs": [],
   "source": [
    "# Bloco para seleção de dispositivo (CUDA, MPS ou CPU)\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    # Prioridade 1: GPU NVIDIA (CUDA)\n",
    "    device = torch.device(\"cuda\")\n",
    "    print(\"Dispositivo selecionado: GPU NVIDIA (CUDA)\")\n",
    "\n",
    "elif torch.backends.mps.is_available():\n",
    "    # Prioridade 2: GPU Apple (MPS)\n",
    "    device = torch.device(\"mps\")\n",
    "    print(\"Dispositivo selecionado: GPU Apple (MPS)\")\n",
    "\n",
    "else:\n",
    "    # Fallback: CPU\n",
    "    device = torch.device(\"cpu\")\n",
    "    print(\"Dispositivo selecionado: CPU\")\n",
    "\n",
    "print(f'Usando dispositivo: {device}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "473e676a-2482-4550-a5bb-8297080fa15e",
   "metadata": {
    "id": "473e676a-2482-4550-a5bb-8297080fa15e"
   },
   "source": [
    "## 3. Definindo Hiperparâmetros Para Treinamento do Modelo de IA\n",
    "\n",
    "Pense nos hiperparâmetros como os \"botões de ajuste\" ou as \"configurações\" que você, <a href=\"https://www.datascienceacademy.com.br/bundle/formacao-engenheiro-de-inteligencia-artificial-4\">Engenheiro de IA</a> ou <a href=\"https://www.datascienceacademy.com.br/bundle/formacao-cientista-de-dados-4\">Cientista de Dados</a>, deve definir antes do treinamento começar. Eles não são aprendidos pelo modelo; eles controlam como o modelo aprende.\n",
    "\n",
    "Aqui está o que cada um desses itens significa:\n",
    "\n",
    "**1. num_epochs = 10 (Número de Épocas)**\n",
    "\n",
    "- O que é: Uma \"época\" representa uma passagem completa do algoritmo por todo o conjunto de dados de treinamento.\n",
    "\n",
    "- O que 10 significa: O modelo \"verá\" e aprenderá com cada exemplo de treinamento um total de 10 vezes.\n",
    "\n",
    "Impacto:\n",
    "\n",
    "- Poucas épocas: O modelo pode não aprender o suficiente (fenômeno chamado underfitting).\n",
    "\n",
    "- Muitas épocas: O modelo pode começar a \"memorizar\" os dados de treinamento em vez de aprender a generalizar, o que o torna ruim em prever novos dados (fenômeno chamado overfitting). Além disso, leva mais tempo.\n",
    "\n",
    "**2. batch_size = 64 (Tamanho do Lote)**\n",
    "\n",
    "- O que é: Em vez de mostrar ao modelo o conjunto de dados inteiro de uma só vez (o que exigiria uma quantidade imensa de memória), nós o dividimos em pequenos \"lotes\" (batches).\n",
    "\n",
    "- O que 64 significa: O modelo processará 64 exemplos de treinamento, calculará o erro médio desse lote e, em seguida, atualizará seus parâmetros (pesos) uma única vez. O processo se repete com os próximos 64 exemplos, e assim por diante, até que todos os dados da época tenham sido vistos.\n",
    "\n",
    "Impacto:\n",
    "\n",
    "- Tamanho maior: Treina mais rápido (usa melhor o paralelismo da GPU), mas pode levar a uma generalização ligeiramente pior. Requer mais memória.\n",
    "\n",
    "- Tamanho menor: Treina mais devagar, mas muitas vezes ajuda o modelo a generalizar melhor (o \"ruído\" nos gradientes de lotes pequenos pode ajudar a evitar mínimos locais ruins).\n",
    "\n",
    "**3. learning_rate = 0.001 (Taxa de Aprendizado)**\n",
    "<!-- Trabalho Desenvolvido no Curso da Data Science Academy - www.datascienceacademy.com.br -->\n",
    "- O que é: Este é, possivelmente, o hiperparâmetro mais importante. Ele controla o \"tamanho do passo\" que o modelo dá ao ajustar seus pesos durante o treinamento.\n",
    "\n",
    "- O que 0.001 significa: Após cada lote, o modelo calcula a direção para corrigir seus erros (o \"gradiente\"). Em vez de fazer uma correção drástica, ele fará uma correção pequena (multiplicada por 0.001) nessa direção.\n",
    "\n",
    "Impacto:\n",
    "\n",
    "- Taxa muito alta: O modelo pode \"pular\" a solução ideal. É como tentar descer uma colina com passos gigantescos; você pode acabar pulando o vale inteiro. O treinamento fica instável e o erro pode até aumentar.\n",
    "\n",
    "- Taxa muito baixa: O modelo aprende muito devagar. Pode levar um tempo excessivo para convergir ou pode ficar \"preso\" em uma solução ruim."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a652229f-6846-4582-aada-be69ee4768bd",
   "metadata": {
    "id": "a652229f-6846-4582-aada-be69ee4768bd"
   },
   "outputs": [],
   "source": [
    "# Hiperparâmetros do modelo\n",
    "num_epochs = 10         # Número de épocas para treinar\n",
    "batch_size = 64         # Tamanho do lote (batch)\n",
    "learning_rate = 0.001   # Taxa de aprendizado"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "095d1666-b0af-4af5-a3d9-101639c55364",
   "metadata": {
    "id": "095d1666-b0af-4af5-a3d9-101639c55364"
   },
   "source": [
    "## 4. Carregando os Dados (Imagens) e Definindo as Transformações, DataLoaders e Classes\n",
    "\n",
    "https://www.cs.toronto.edu/~kriz/cifar.html\n",
    "   \n",
    "Você precisa dessa linha abaixo para padronizar os dados de imagens antes de entregá-los ao modelo de IA. Redes neurais não entendem imagens; elas entendem números. Esse código faz duas coisas essenciais:\n",
    "\n",
    "- transforms.ToTensor(): Converte a imagem (que tem valores de pixel de 0 a 255) em um Tensor do PyTorch (a \"linguagem\" que a IA entende) e, o mais importante, ajusta a escala desses valores para um intervalo de [0.0, 1.0].\n",
    "\n",
    "- transforms.Normalize((0.5,...), (0.5,...)): Pega esses valores [0.0, 1.0] e os centraliza, mudando o intervalo para [-1.0, 1.0]. (Matematicamente: (valor - 0.5) / 0.5).\n",
    "\n",
    "Por que fazer isso? Modelos de IA treinam de forma muito mais rápida, eficiente e estável quando os números de entrada estão padronizados e centrados em zero (como [-1, 1]) em vez de [0, 255]. Isso ajuda o modelo a aprender melhor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bd86aca-6621-4ec4-8750-915e37c6955b",
   "metadata": {
    "id": "6bd86aca-6621-4ec4-8750-915e37c6955b"
   },
   "outputs": [],
   "source": [
    "# Definir as transformações para os dados\n",
    "transformacoes = transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c52024d-a056-48bb-8668-91fc3f645a8d",
   "metadata": {
    "id": "9c52024d-a056-48bb-8668-91fc3f645a8d"
   },
   "outputs": [],
   "source": [
    "# Baixar e carregar o dataset de treino\n",
    "dataset_treino = torchvision.datasets.CIFAR10(root = './dados',\n",
    "                                                  train = True,\n",
    "                                                  download = True,\n",
    "                                                  transform = transformacoes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53f08551-3caa-4f1c-a4a1-4163eba86b80",
   "metadata": {
    "id": "53f08551-3caa-4f1c-a4a1-4163eba86b80"
   },
   "outputs": [],
   "source": [
    "# Baixar e carregar o dataset de teste\n",
    "dataset_teste = torchvision.datasets.CIFAR10(root = './dados',\n",
    "                                                 train = False,\n",
    "                                                 download = True,\n",
    "                                                 transform = transformacoes)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "faa6752b-c481-4827-89a7-a44fba5101c3",
   "metadata": {
    "id": "faa6752b-c481-4827-89a7-a44fba5101c3"
   },
   "source": [
    "Precisamos dos DataLoaders para automatizar e otimizar a entrega dos dados ao modelo durante o treinamento e teste. Eles resolvem três problemas principais:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb8ddf9b-5ae1-47a8-84d9-6f4c42022a29",
   "metadata": {
    "id": "cb8ddf9b-5ae1-47a8-84d9-6f4c42022a29"
   },
   "source": [
    "- Gerenciamento de Memória (Lotes): Seu dataset (dataset_treino) pode ter 100.000 imagens. Elas não cabem todas na memória de uma só vez. O DataLoader pega esse dataset e o serve em \"lotes\" pequenos (definidos pelo batch_size = 64), um de cada vez."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a6988c3-b619-4b7a-ad10-7c61ee62193b",
   "metadata": {
    "id": "5a6988c3-b619-4b7a-ad10-7c61ee62193b"
   },
   "source": [
    "- Embaralhamento (Evitar Vício):\n",
    "\n",
    "        shuffle=True (para treino): A cada época, ele embaralha os dados de treino. Isso é vital para que o modelo não aprenda a ordem dos dados e generalize melhor.\n",
    "\n",
    "        shuffle=False (para teste): Garante que os dados de teste sejam sempre avaliados na mesma ordem, permitindo comparações justas do desempenho do modelo."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e8a9d27-371f-4058-bdc4-1ae138806e0b",
   "metadata": {
    "id": "0e8a9d27-371f-4058-bdc4-1ae138806e0b"
   },
   "source": [
    "- Eficiência (Paralelismo): O DataLoader pode usar múltiplos \"trabalhadores\" (processos) para carregar os próximos lotes de dados enquanto a GPU ainda está processando o lote atual, evitando gargalos e acelerando o treinamento."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "787650c1-bb94-4424-8422-cac79b0b6233",
   "metadata": {
    "id": "787650c1-bb94-4424-8422-cac79b0b6233"
   },
   "outputs": [],
   "source": [
    "# Criar os DataLoaders para carregar os dados em lotes\n",
    "loader_treino = torch.utils.data.DataLoader(dataset_treino,\n",
    "                                                batch_size = batch_size,\n",
    "                                                shuffle = True)\n",
    "\n",
    "loader_teste = torch.utils.data.DataLoader(dataset_teste,\n",
    "                                               batch_size = batch_size,\n",
    "                                               shuffle = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7dfb777e-5e8c-4efa-b8a1-838f13146ee9",
   "metadata": {
    "id": "7dfb777e-5e8c-4efa-b8a1-838f13146ee9"
   },
   "outputs": [],
   "source": [
    "# Definir as classes do CIFAR-10\n",
    "classes = ('plane', 'car', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02813265-9a62-436e-bbe8-7a38cd0b2381",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "02813265-9a62-436e-bbe8-7a38cd0b2381",
    "outputId": "cd23b788-c466-4f59-a438-f9da9eed4599"
   },
   "outputs": [],
   "source": [
    "print(f\"Número de imagens de treino: {len(dataset_treino)}\")\n",
    "print(f\"Número de imagens de teste: {len(dataset_teste)}\")\n",
    "print(f\"Número de lotes (batches) de treino: {len(loader_treino)}\")\n",
    "print(f\"Número de lotes (batches) de teste: {len(loader_teste)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "123c60c0-b7bc-4ae7-bc63-e6a42fd1d522",
   "metadata": {
    "id": "123c60c0-b7bc-4ae7-bc63-e6a42fd1d522"
   },
   "source": [
    "<!-- Trabalho Desenvolvido no Curso da Data Science Academy - www.datascienceacademy.com.br -->"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "341519ea-09a5-436c-be43-cfb1e964e9a4",
   "metadata": {
    "id": "341519ea-09a5-436c-be43-cfb1e964e9a4"
   },
   "source": [
    "## 5. Visualizando as Imagens Carregadas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3970c5e4-f537-4538-8b7e-2aca58a2931e",
   "metadata": {
    "id": "3970c5e4-f537-4538-8b7e-2aca58a2931e"
   },
   "outputs": [],
   "source": [
    "# Função para mostrar a imagem\n",
    "def imshow(img):\n",
    "    img = img / 2 + 0.5                          # Desnormaliza (de [-1, 1] para [0, 1])\n",
    "    npimg = img.numpy()                          # Converte a imagem em formato de matriz NumPy\n",
    "    plt.imshow(np.transpose(npimg, (1, 2, 0)))   # Converte de (C, H, W) para (H, W, C) - Canais (C), Altura (H) e Largura (W)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61d9888e-b25c-4c07-8ce2-523e792e267b",
   "metadata": {
    "id": "61d9888e-b25c-4c07-8ce2-523e792e267b"
   },
   "outputs": [],
   "source": [
    "# Obtém um lote de imagens de treino\n",
    "dataiter = iter(loader_treino)\n",
    "images, labels = next(dataiter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3604ce5a-c52f-45a5-819e-2c713c40e81d",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 229
    },
    "id": "3604ce5a-c52f-45a5-819e-2c713c40e81d",
    "outputId": "0b10a440-dece-4dad-ac35-a57029811cb3"
   },
   "outputs": [],
   "source": [
    "# Mostra as primeiras 4 imagens do lote\n",
    "print(\"Amostra de imagens de treino:\")\n",
    "imshow(torchvision.utils.make_grid(images[:4]))\n",
    "\n",
    "# Imprime os labels correspondentes\n",
    "print('Labels: ', ' '.join(f'{classes[labels[j]]:5s}' for j in range(4)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e7032ba-9c16-4414-8353-49908f329633",
   "metadata": {
    "id": "1e7032ba-9c16-4414-8353-49908f329633"
   },
   "source": [
    "## 6. Construção do Modelo de IA\n",
    "\n",
    "A célula abaixo define a arquitetura de uma Rede Neural Convolucional (CNN), um modelo de IA clássico usado para classificação de imagens.\n",
    "\n",
    "https://www.deeplearningbook.com.br/introducao-as-redes-neurais-convolucionais/\n",
    "\n",
    "De forma resumida, ele é dividido em duas partes:\n",
    "\n",
    "**__init__(self) (A \"Planta\" da Rede):**\n",
    "\n",
    "- Esta função é o \"construtor\" que declara todas as camadas (as \"peças\") que a rede irá usar.\n",
    "\n",
    "- self.conv1 e self.conv2: São camadas convolucionais que atuam como \"extratores de características\", aprendendo a identificar padrões (como bordas, texturas) na imagem.\n",
    "\n",
    "- self.pool: É uma camada de pooling que reduz o tamanho da imagem (de 28x28 para 14x14, e de 10x10 para 5x5), tornando o modelo mais eficiente e focado nas características mais importantes.\n",
    "\n",
    "- self.fc1, fc2, fc3: São camadas lineares (totalmente conectadas) que atuam como o \"cérebro\" de decisão. Elas recebem as características achatadas (16 * 5 * 5 = 400) e as usam para classificar a imagem. A última camada (fc3) tem 10 saídas, uma para cada categoria final (ex: \"gato\", \"cachorro\", \"avião\", etc.).\n",
    "\n",
    "**forward(self, x) (A \"Linha de Montagem\"):**\n",
    "\n",
    "- Esta função define a ordem exata em que os dados (x, a imagem de entrada) passam pelas camadas.\n",
    "\n",
    "- O fluxo é: Convolução 1 -> Ativação ReLU -> Pooling -> Convolução 2 -> Ativação ReLU -> Pooling.\n",
    "\n",
    "- Após extrair as características, os dados são \"achatados\" (flatten) para se tornarem um vetor longo.\n",
    "\n",
    "- Esse vetor passa pelas camadas de decisão (fc1, fc2, fc3) para produzir o resultado final da classificação."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c6628dc-d6fd-4bdd-8d20-7d9920f705ae",
   "metadata": {
    "id": "6c6628dc-d6fd-4bdd-8d20-7d9920f705ae"
   },
   "outputs": [],
   "source": [
    "# Classe para criar a arquitetura do modelo\n",
    "class ConvNet(nn.Module):\n",
    "\n",
    "    # Método construtor\n",
    "    def __init__(self):\n",
    "\n",
    "        # Inicializa o construtor da classe mãe\n",
    "        super(ConvNet, self).__init__()\n",
    "\n",
    "        # Input: 3 canais de cor, Output: 6 feature maps, Kernel: 5x5\n",
    "        self.conv1 = nn.Conv2d(3, 6, 5)\n",
    "\n",
    "        # Max pooling 2x2\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "\n",
    "        # Input: 6 canais (do conv1), Output: 16 feature maps, Kernel: 5x5\n",
    "        self.conv2 = nn.Conv2d(6, 16, 5)\n",
    "\n",
    "        # As imagens CIFAR-10 são 32x32\n",
    "        # Após conv1 (5x5): 32-5+1 = 28 -> 28x28\n",
    "        # Após pool1 (2x2): 28/2 = 14 -> 14x14\n",
    "        # Após conv2 (5x5): 14-5+1 = 10 -> 10x10\n",
    "        # Após pool2 (2x2): 10/2 = 5 -> 5x5\n",
    "        # Tamanho achatado (flattened): 16 canais * 5 * 5 = 400 atributos\n",
    "\n",
    "        # Camadas totalmente conectadas (Linear)\n",
    "        self.fc1 = nn.Linear(16 * 5 * 5, 120) # 400 -> 120\n",
    "        self.fc2 = nn.Linear(120, 84)         # 120 -> 84\n",
    "        self.fc3 = nn.Linear(84, 10)          # 84 -> 10 (10 classes)\n",
    "\n",
    "    # Método forward (passada para a frente)\n",
    "    def forward(self, x):\n",
    "\n",
    "        # Aplicando as camadas convolucionais e pooling\n",
    "        x = self.pool(F.relu(self.conv1(x)))\n",
    "        x = self.pool(F.relu(self.conv2(x)))\n",
    "\n",
    "        # Achatar (flatten) o tensor para a camada linear\n",
    "        # Achata todas as dimensões, exceto o batch\n",
    "        x = torch.flatten(x, 1)\n",
    "\n",
    "        # Aplicando as camadas lineares com ReLU\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "\n",
    "        # Camada de saída (sem ativação, pois a CrossEntropyLoss aplica Softmax)\n",
    "        x = self.fc3(x)\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad4970d7-475b-47c4-95b5-dfaf4765785f",
   "metadata": {
    "id": "ad4970d7-475b-47c4-95b5-dfaf4765785f"
   },
   "outputs": [],
   "source": [
    "# Vamos instanciar o modelo e movê-lo para a CPU para visualizarmos um resumo do modelo\n",
    "modelo = ConvNet().to(\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1179ca85-5f2b-4bc0-abfa-20b504ce3744",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "1179ca85-5f2b-4bc0-abfa-20b504ce3744",
    "outputId": "9deea6db-cba8-4ef6-8298-7205109e9338"
   },
   "outputs": [],
   "source": [
    "print(\"Arquitetura do Modelo:\")\n",
    "print(modelo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "706c7a28-574b-4256-91ba-bffc790939d1",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "706c7a28-574b-4256-91ba-bffc790939d1",
    "outputId": "61fccd16-f446-4e47-ae41-386fb52b2378"
   },
   "outputs": [],
   "source": [
    "# Sumário\n",
    "summary(modelo, (3, 32, 32), device = \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97896335-68e3-4f46-b29b-1bf95fe76048",
   "metadata": {
    "id": "97896335-68e3-4f46-b29b-1bf95fe76048"
   },
   "outputs": [],
   "source": [
    "# Agora instanciamos o modelo e movemos para o dispositivo de treino (GPU/CPU)\n",
    "modelo = ConvNet().to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ba91be1-5268-46d3-a6fa-5e1c02bd81df",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "3ba91be1-5268-46d3-a6fa-5e1c02bd81df",
    "outputId": "b6ec5322-12dd-4067-ba92-a771624421ed"
   },
   "outputs": [],
   "source": [
    "print(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2de47036-f493-403b-b763-9305e945cdb8",
   "metadata": {
    "id": "2de47036-f493-403b-b763-9305e945cdb8"
   },
   "source": [
    "## 7. Definindo a Função de Perda e Otimizador (Backpropagation)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9ff9da2-0ad3-4763-a34d-ba7089ab3cfc",
   "metadata": {
    "id": "b9ff9da2-0ad3-4763-a34d-ba7089ab3cfc"
   },
   "source": [
    "Esta é a função de perda (ou \"critério\"). Ela atua como uma \"régua\" que mede o quão distante as previsões do seu modelo estão das respostas corretas.\n",
    "\n",
    "Em problemas de classificação (como \"gato\" vs \"cachorro\" vs \"avião\"), CrossEntropyLoss é a métrica padrão. Durante o treinamento, ela calcula um único número (a \"perda\") que indica o tamanho do erro. O objetivo de todo o treinamento é minimizar esse número."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b95d7adb-f7b3-4504-a559-c12aa3ccb7ed",
   "metadata": {
    "id": "b95d7adb-f7b3-4504-a559-c12aa3ccb7ed"
   },
   "outputs": [],
   "source": [
    "# Define a função de perda. O modelo vai buscar os parâmetros que reduzem o erro geral das previsões.\n",
    "criterion = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e0bcb1c-58e3-4384-b488-beb40dab68a2",
   "metadata": {
    "id": "9e0bcb1c-58e3-4384-b488-beb40dab68a2"
   },
   "source": [
    "Este é o otimizador. Se a função de perda é a \"régua\" que mede o erro, o otimizador é o \"mecânico\" que corrige o erro.\n",
    "\n",
    "O otimizador \"olha\" para o erro (calculado pela criterion) e decide exatamente como ajustar cada parâmetro (peso) dentro do modelo.parameters() para reduzir esse erro no próximo passo.\n",
    "\n",
    "Adam é um algoritmo de otimização moderno e muito popular porque é eficiente e se ajusta automaticamente (adaptativo), funcionando bem na maioria dos casos sem exigir muito ajuste manual. O lr = learning_rate apenas diz a ele o quão \"agressivo\" deve ser esse ajuste."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b55b53a-5d36-4e8d-b175-07c960085a64",
   "metadata": {
    "id": "6b55b53a-5d36-4e8d-b175-07c960085a64"
   },
   "outputs": [],
   "source": [
    "# Otimizador Adam\n",
    "optimizer = optim.Adam(modelo.parameters(), lr = learning_rate)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc8c52cd-b91d-430a-96e3-16dbc0e2f3a4",
   "metadata": {
    "id": "bc8c52cd-b91d-430a-96e3-16dbc0e2f3a4"
   },
   "source": [
    "## 8. Treinamento do Modelo\n",
    "\n",
    "A célula abaixo é o \"coração\" do processo de treinamento e validação do seu modelo de IA. De forma resumida, ele faz o seguinte:\n",
    "\n",
    "Loop Principal de Épocas (for epoch...): Este é o loop externo. Ele faz o modelo \"estudar\" o conjunto de dados de treinamento inteiro várias vezes (o número de vezes é definido por num_epochs).\n",
    "<!-- Trabalho Desenvolvido no Curso da Data Science Academy - www.datascienceacademy.com.br -->\n",
    "Dentro de cada \"Época\", existem duas fases:\n",
    "\n",
    "**1. Fase de Treinamento (modelo.train())**\n",
    "\n",
    "Nesta fase, o modelo aprende com os dados:\n",
    "\n",
    "- for i, (images, labels)...: Pega os dados de treino em pequenos lotes (ex: 64 imagens de cada vez).\n",
    "\n",
    "- images.to(device): Move os dados para a GPU para processamento rápido.\n",
    "\n",
    "- outputs = modelo(images): (Forward) Faz as previsões do modelo para o lote de imagens.\n",
    "\n",
    "- loss = criterion(...): Calcula o \"erro\" (quão ruins foram as previsões) comparando outputs com os rótulos corretos (labels).\n",
    "\n",
    "- optimizer.zero_grad(): Limpa os cálculos de erro da etapa anterior.\n",
    "\n",
    "- loss.backward(): (Backward) Calcula \"para trás\" como cada peso do modelo contribuiu para esse erro (calcula os gradientes).\n",
    "\n",
    "- optimizer.step(): Usa o otimizador (Adam) para ajustar todos os pesos do modelo e reduzir o erro.\n",
    "\n",
    "**2. Fase de Avaliação (modelo.eval())**\n",
    "\n",
    "Após estudar os dados de treino uma vez, o modelo \"faz uma prova\" para ver o que aprendeu:\n",
    "\n",
    "- modelo.eval(): Coloca o modelo em modo de avaliação (desliga recursos como dropout).\n",
    "\n",
    "- with torch.no_grad(): Desativa o cálculo de gradientes (pois não vamos treinar), o que economiza muita memória e acelera o processo.\n",
    "\n",
    "- for val_images, val_labels...: Pega os dados do conjunto de teste (dados que o modelo nunca viu no treino).\n",
    "\n",
    "- val_outputs = modelo(val_images): Faz previsões sobre os dados de teste.\n",
    "\n",
    "- n_correct += ...: Compara as previsões do modelo com as respostas corretas e conta o número total de acertos.\n",
    "\n",
    "**3. Relatório de Progresso**\n",
    "\n",
    "- print(f'Epoch ...'): No final de cada época, ele imprime um resumo: o erro médio do treinamento e a acurácia (percentual de acertos) no teste, permitindo que você veja o modelo melhorar ao longo do tempo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36d66643-fafe-456c-98ad-6e126917b268",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "36d66643-fafe-456c-98ad-6e126917b268",
    "outputId": "7a3044c5-20d1-48a8-d05c-5de8d36e2e65"
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "print(\"\\nIniciando o treinamento...\\n\")\n",
    "\n",
    "# Calcula o total de passos por época (número de batches)\n",
    "n_total_steps = len(loader_treino)\n",
    "\n",
    "# Loop principal de treinamento\n",
    "for epoch in range(num_epochs):\n",
    "\n",
    "    # Coloca o modelo em modo de treinamento\n",
    "    modelo.train()\n",
    "\n",
    "    # Inicializa o acumulador de perda\n",
    "    running_loss = 0.0\n",
    "\n",
    "    # Itera sobre os batches do conjunto de treino\n",
    "    for i, (images, labels) in enumerate(loader_treino):\n",
    "\n",
    "        # Move os tensores (imagens e rótulos) para o dispositivo (CPU ou GPU), próximos do modelo\n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "\n",
    "        # Passagem para frente (forward)\n",
    "        # Aqui ocorre a previsão do modelo\n",
    "        outputs = modelo(images)\n",
    "\n",
    "        # Calcula o erro do modelo\n",
    "        loss = criterion(outputs, labels)\n",
    "\n",
    "        # Zera os gradientes acumulados de iterações anteriores\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # Calcula os gradientes via backpropagation\n",
    "        loss.backward()\n",
    "\n",
    "        # Atualiza os pesos do modelo\n",
    "        optimizer.step()\n",
    "\n",
    "        # Soma o valor da perda para cálculo médio posterior\n",
    "        running_loss += loss.item()\n",
    "\n",
    "    # Após cada época, avalia o modelo no conjunto de teste (validação)\n",
    "    # Coloca o modelo em modo de avaliação\n",
    "    modelo.eval()\n",
    "\n",
    "    # Desativa o cálculo de gradientes para economizar memória e tempo\n",
    "    with torch.no_grad():\n",
    "\n",
    "        n_correct = 0   # Contador de acertos\n",
    "        n_samples = 0   # Contador de amostras\n",
    "\n",
    "        # Loop sobre o conjunto de teste\n",
    "        for val_images, val_labels in loader_teste:\n",
    "\n",
    "            # Move imagens e rótulos para o dispositivo\n",
    "            val_images = val_images.to(device)\n",
    "            val_labels = val_labels.to(device)\n",
    "\n",
    "            # Faz a inferência no conjunto de teste\n",
    "            val_outputs = modelo(val_images)\n",
    "\n",
    "            # torch.max retorna (valor, índice) → pegamos o índice da classe prevista\n",
    "            _, predicted = torch.max(val_outputs.data, 1)\n",
    "\n",
    "            # Incrementa o total de amostras\n",
    "            n_samples += val_labels.size(0)\n",
    "\n",
    "            # Incrementa o número de acertos\n",
    "            n_correct += (predicted == val_labels).sum().item()\n",
    "\n",
    "    # Calcula a acurácia e a perda média da época\n",
    "    acc = 100.0 * n_correct / n_samples\n",
    "    avg_loss = running_loss / n_total_steps\n",
    "\n",
    "    # Exibe métricas de desempenho para a época atual\n",
    "    print(f'Epoch [{epoch+1}/{num_epochs}], Erro em Treino: {avg_loss:.4f}, Acurácia em Teste: {acc:.2f} %')\n",
    "\n",
    "# Exibe mensagem final de conclusão\n",
    "print('\\nTreinamento finalizado.\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3160a943-b57f-4a40-8599-9c3eaeb288c5",
   "metadata": {
    "id": "3160a943-b57f-4a40-8599-9c3eaeb288c5"
   },
   "source": [
    "## 9. Avaliação do Modelo\n",
    "\n",
    "Este bloco de código é responsável por executar a avaliação final do modelo usando o conjunto de dados de teste, que ele nunca viu durante o treinamento. Primeiramente, modelo.eval() coloca a rede em \"modo de avaliação\", o que desativa camadas específicas de treino (como dropout). Em seguida, with torch.no_grad() desativa o cálculo de gradientes, pois o modelo não está mais aprendendo; isso economiza memória e acelera muito o processo de inferência.\n",
    "\n",
    "O código então itera por todos os lotes do loader_teste. Para cada lote, ele faz as previsões (outputs), usa torch.max para extrair a classe com a maior pontuação (a previsão final, predicted), e compara com os rótulos verdadeiros (labels). Ele acumula o número total de amostras (n_samples) e o número total de acertos (n_correct) para calcular a acurácia geral do modelo.\n",
    "\n",
    "Simultaneamente, o loop interno (for i in range(len(labels))) realiza uma análise mais detalhada. Ele verifica o resultado de cada imagem individualmente para calcular a acurácia por classe, preenchendo as listas n_class_correct e n_class_samples. Ao final, o script imprime a acurácia geral (ex: 85%) e, em seguida, detalha a performance para cada classe específica (ex: Acurácia da classe 'gato': 90%, Acurácia da classe 'cachorro': 75%), permitindo uma análise mais profunda de onde o modelo está acertando ou errando."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "532add11-bf9b-4c58-aa1f-246f66a8dd6c",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "532add11-bf9b-4c58-aa1f-246f66a8dd6c",
    "outputId": "1c53697a-c77e-408e-d0e8-17d843a202ec"
   },
   "outputs": [],
   "source": [
    "# Coloca o modelo em modo de avaliação\n",
    "modelo.eval()\n",
    "\n",
    "# Desativa o cálculo de gradientes (não é necessário durante a avaliação)\n",
    "with torch.no_grad():\n",
    "\n",
    "    # Inicializa contador de acertos totais\n",
    "    n_correct = 0\n",
    "\n",
    "    # Inicializa contador total de amostras\n",
    "    n_samples = 0\n",
    "\n",
    "    # Lista para contar acertos por classe\n",
    "    n_class_correct = [0 for _ in range(10)]\n",
    "\n",
    "    # Lista para contar total de amostras por classe\n",
    "    n_class_samples = [0 for _ in range(10)]\n",
    "\n",
    "    # Loop sobre o conjunto de teste\n",
    "    for images, labels in loader_teste:\n",
    "\n",
    "        # Move imagens para o dispositivo (CPU ou GPU)\n",
    "        images = images.to(device)\n",
    "\n",
    "        # Move rótulos para o mesmo dispositivo\n",
    "        labels = labels.to(device)\n",
    "\n",
    "        # Faz a inferência com o modelo\n",
    "        outputs = modelo(images)\n",
    "\n",
    "        # Obtém as classes com maior probabilidade\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "\n",
    "        # Incrementa o número total de amostras\n",
    "        n_samples += labels.size(0)\n",
    "\n",
    "        # Incrementa o número total de acertos\n",
    "        n_correct += (predicted == labels).sum().item()\n",
    "\n",
    "        # Calcular acurácia por classe\n",
    "        for i in range(len(labels)):\n",
    "\n",
    "            # Obtém o rótulo verdadeiro\n",
    "            label = labels[i]\n",
    "\n",
    "            # Obtém o rótulo previsto\n",
    "            pred = predicted[i]\n",
    "\n",
    "            # Se acertou, incrementa o contador da classe\n",
    "            if (label == pred):\n",
    "                n_class_correct[label] += 1\n",
    "\n",
    "            # Incrementa o total de amostras da classe\n",
    "            n_class_samples[label] += 1\n",
    "\n",
    "    # Calcula a acurácia geral do modelo\n",
    "    acc_geral = 100.0 * n_correct / n_samples\n",
    "\n",
    "    # Exibe o resultado da acurácia geral\n",
    "    print(f'Acurácia geral do modelo na base de teste: {acc_geral:.2f} %')\n",
    "\n",
    "    # Imprime linha separadora\n",
    "    print(\"-\" * 30)\n",
    "\n",
    "    # Loop para calcular e exibir acurácia de cada classe\n",
    "    for i in range(10):\n",
    "\n",
    "        # Se houver amostras para a classe\n",
    "        if n_class_samples[i] > 0:\n",
    "\n",
    "            # Calcula a acurácia da classe\n",
    "            acc_classe = 100.0 * n_class_correct[i] / n_class_samples[i]\n",
    "\n",
    "            # Exibe acurácia da classe\n",
    "            print(f'Acurácia da classe {classes[i]}: {acc_classe:.2f} %')\n",
    "\n",
    "        # Caso não existam amostras da classe\n",
    "        else:\n",
    "\n",
    "            # Indica ausência de dados para a classe\n",
    "            print(f'Acurácia da classe {classes[i]}: N/A (sem amostras)')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7bf62c4-6288-43bb-8034-d2abadf04091",
   "metadata": {
    "id": "d7bf62c4-6288-43bb-8034-d2abadf04091"
   },
   "source": [
    "Vamos salvar o modelo em disco."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcc44c16-15b0-4e19-9b12-dac038ee4fe9",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "bcc44c16-15b0-4e19-9b12-dac038ee4fe9",
    "outputId": "eef74fe9-6a10-4615-8e64-f434a26d0cb1"
   },
   "outputs": [],
   "source": [
    "PATH = './modelo_mp7.pth'\n",
    "torch.save(modelo.state_dict(), PATH)\n",
    "print(f'Modelo salvo em: {PATH}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "077dff2e-35e2-4099-86cc-ee39707bf1d5",
   "metadata": {
    "id": "077dff2e-35e2-4099-86cc-ee39707bf1d5"
   },
   "source": [
    "## 10. Deploy e Uso do Modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de08ad6d-5fdf-4b55-b3fb-18743825f1c1",
   "metadata": {
    "id": "de08ad6d-5fdf-4b55-b3fb-18743825f1c1"
   },
   "outputs": [],
   "source": [
    "# Cria uma nova instância do modelo\n",
    "model_carregado = ConvNet().to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "893f39e3-ed09-462c-b014-589112b343c6",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "893f39e3-ed09-462c-b014-589112b343c6",
    "outputId": "3e17a9eb-f7d2-4d5f-f4d5-29a1d0d68a14"
   },
   "outputs": [],
   "source": [
    "# Carrega os pesos (state_dict) salvos\n",
    "model_carregado.load_state_dict(torch.load(PATH))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c87bc6b-ba0d-4e79-9b8f-e0e4a64e75c8",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "3c87bc6b-ba0d-4e79-9b8f-e0e4a64e75c8",
    "outputId": "54c76085-ef49-41cc-e1bf-e5f67932a77d"
   },
   "outputs": [],
   "source": [
    "# IMPORTANTE: Colocar o modelo em modo de avaliação\n",
    "model_carregado.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95301dd9-35cc-408b-99d0-7927ee9d1d01",
   "metadata": {
    "id": "95301dd9-35cc-408b-99d0-7927ee9d1d01"
   },
   "outputs": [],
   "source": [
    "# Definir a transformação para imagens de inferência\n",
    "# Deve ser a MESMA transformação usada no treino/teste\n",
    "# (Exceto por augmentations, que não usamos aqui)\n",
    "inference_transform = transforms.Compose([\n",
    "    transforms.Resize((32, 32)), # Garantir que a imagem tenha 32x32\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "665d4b52-6075-4f64-8cf8-fa256ed237b6",
   "metadata": {
    "id": "665d4b52-6075-4f64-8cf8-fa256ed237b6"
   },
   "outputs": [],
   "source": [
    "# Cria a função de deploy\n",
    "def ia_classifica_imagem(image_path, model):\n",
    "\n",
    "    \"\"\"\n",
    "    Carrega uma imagem de um caminho local, aplica as transformações\n",
    "    e faz a predição usando o modelo treinado.\n",
    "    \"\"\"\n",
    "\n",
    "    try:\n",
    "        # Carregar imagem do caminho local\n",
    "        img_pil = Image.open(image_path).convert('RGB')\n",
    "    except Exception as e:\n",
    "        print(f\"Erro ao carregar imagem local {image_path}: {e}\")\n",
    "        return\n",
    "\n",
    "    # Aplicar transformações\n",
    "    img_tensor = inference_transform(img_pil)\n",
    "\n",
    "    # O modelo espera um lote (batch). Adicionamos uma dimensão extra [B, C, H, W]\n",
    "    img_tensor = img_tensor.unsqueeze(0).to(device)\n",
    "\n",
    "    # Fazer a predição\n",
    "    model.eval() # Garantir que o modelo está em modo de avaliação\n",
    "    with torch.no_grad():\n",
    "\n",
    "        outputs = model(img_tensor)\n",
    "\n",
    "        probabilities = F.softmax(outputs, dim=1)\n",
    "\n",
    "        # Obter a classe com maior probabilidade\n",
    "        _, predicted_idx = torch.max(outputs, 1)\n",
    "\n",
    "    classe_predita = classes[predicted_idx.item()]\n",
    "\n",
    "    confianca = torch.max(probabilities).item() * 100\n",
    "\n",
    "    # Mostrar a imagem e a predição\n",
    "    plt.imshow(img_pil)\n",
    "\n",
    "    # Usamos rf'...' (raw f-string) e $\\bf{...}$ para negrito\n",
    "    plt.title(rf'Classe Prevista Pelo Modelo: $\\bf{{{classe_predita}}}$ (Confiança: {confianca:.2f}%)')\n",
    "    plt.axis('off')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d053a39-d4c0-46c9-82cc-2bc075999289",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 430
    },
    "id": "1d053a39-d4c0-46c9-82cc-2bc075999289",
    "outputId": "8a552a84-beb1-4ecb-d3d4-199025b6d875"
   },
   "outputs": [],
   "source": [
    "# Usamos o modelo para classificar a imagem\n",
    "ia_classifica_imagem(\"imagem1.jpg\", model_carregado)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "489f5420-77c8-46af-b9c9-4eba0ff36658",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 430
    },
    "id": "489f5420-77c8-46af-b9c9-4eba0ff36658",
    "outputId": "4d81279f-489b-47ae-a658-a180ffde368d"
   },
   "outputs": [],
   "source": [
    "# Usamos o modelo para classificar a imagem\n",
    "ia_classifica_imagem(\"imagem2.jpg\", model_carregado)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08e7dd21-b17b-47f1-8ae5-f69e7c4fe18e",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 371
    },
    "id": "08e7dd21-b17b-47f1-8ae5-f69e7c4fe18e",
    "outputId": "e50222ea-f895-4e72-cdc8-8835b18f0fc3"
   },
   "outputs": [],
   "source": [
    "# Usamos o modelo para classificar a imagem\n",
    "ia_classifica_imagem(\"imagem3.png\", model_carregado)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb2a0603-c88c-47fa-aaee-028bbdd0357e",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 340
    },
    "id": "eb2a0603-c88c-47fa-aaee-028bbdd0357e",
    "outputId": "a1e6c400-f7be-47a9-a4a1-4b9e36e371cf"
   },
   "outputs": [],
   "source": [
    "# Usamos o modelo para classificar a imagem\n",
    "ia_classifica_imagem(\"imagem4.jpg\", model_carregado)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c898a085-0c28-4122-8492-bfbffcd5ccee",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 412
    },
    "id": "c898a085-0c28-4122-8492-bfbffcd5ccee",
    "outputId": "6ecc4c41-792a-4fbf-d306-f44d41a34c72"
   },
   "outputs": [],
   "source": [
    "# Usamos o modelo para classificar a imagem\n",
    "ia_classifica_imagem(\"imagem5.jpg\", model_carregado)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "DQ983QNak70f",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 430
    },
    "id": "DQ983QNak70f",
    "outputId": "6c9552ce-c47e-434f-d697-2f0f4c897699"
   },
   "outputs": [],
   "source": [
    "# Usamos o modelo para classificar a imagem (observe que o modelo não foi treinado com imagens de maçãs)\n",
    "ia_classifica_imagem(\"imagem6.jpg\", model_carregado)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7276514-db94-4f21-bd7f-e43403597daf",
   "metadata": {
    "id": "b7276514-db94-4f21-bd7f-e43403597daf"
   },
   "source": [
    "## Bônus - Comparando a Execução em Diferentes Tipos de Hardware\n",
    "\n",
    "O objetivo aqui é apenas ter uma ideia geral da diferença de hardware no treinamento do modelo.\n",
    "\n",
    "- 1- Apple M4 Max com GPU - 45.4 s\n",
    "- 2- Apple M4 Max sem GPU - 1min 40s\n",
    "- 3- Google Colab com GPU A100 (High RAM) - 2min 33s\n",
    "- 4- Google Colab com GPU A100 - 2min 34s\n",
    "- 5- Google Colab com GPU T4 - 2min 32s\n",
    "- 6- Google Colab com CPU - 3min 34s"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cbe2317-98f9-454e-ac16-73b53ed68178",
   "metadata": {
    "id": "3cbe2317-98f9-454e-ac16-73b53ed68178"
   },
   "source": [
    "# Fim"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "A100",
   "machine_shape": "hm",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
